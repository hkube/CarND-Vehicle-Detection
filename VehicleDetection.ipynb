{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Nanaodegree Program \"Self Driving Car Engineer\"\n",
    "## Vehicle Detection Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "import cv2\n",
    "import glob\n",
    "import imp\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt \n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_img_names =  glob.glob(\"training_data/cars/*/*\")\n",
    "notcar_img_names = glob.glob(\"training_data/notcars/*/*\")\n",
    "print(\"training images - cars:\", len(car_img_names), \"   notcars:\", len(notcar_img_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a functions to convert the colorspace of an image and to get the hog features\n",
    "This code was taken from the lesson materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    print(\"Error: Color space {:s} is not supported!\".format(conv))\n",
    "    return None\n",
    "\n",
    "    \n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "    \n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to extract the HOG features from an array of car images and non-car images\n",
    "This code was taken from the lesson materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if False:\n",
    "                feature_image = convert_color(image, \"RGB2\"+color_space)\n",
    "            else:\n",
    "                if color_space == 'HSV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "                elif color_space == 'LUV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "                elif color_space == 'HLS':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "                elif color_space == 'YUV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "                elif color_space == 'YCrCb':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: \n",
    "            feature_image = np.copy(image)      \n",
    "\n",
    "        if hog_feat == True:\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the feature from the training images and combine them with the appropriate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "# COLORSPACE is one out of \"BGR\", \"HSV\", \"LUV\", \"HLS\", \"YUV\", \"YCrCb\"\n",
    "COLORSPACE = \"YCrCb\"\n",
    "# HOG extraction parameters\n",
    "ORIENTATION = 9\n",
    "PIX_PER_CELL = 8\n",
    "CELL_PER_BLOCK = 2\n",
    "# HOG_CHANNEL is one out of 0, 1, 2, \"ALL\"\n",
    "HOG_CHANNEL = \"ALL\"\n",
    "HIST_FEAT = False\n",
    "SPATIAL_FEAT = False\n",
    "\n",
    "print(\"HOG parameters: orient:\", ORIENTATION, \" pix_per_cell:\", PIX_PER_CELL, \" cell_per_block:\", CELL_PER_BLOCK, \" channel:\", HOG_CHANNEL)\n",
    "\n",
    "t0 = time.time()\n",
    "car_features = extract_features(car_img_names, color_space=COLORSPACE, orient=ORIENTATION,\n",
    "                                pix_per_cell=PIX_PER_CELL, cell_per_block=CELL_PER_BLOCK,\n",
    "                                hog_channel=HOG_CHANNEL, \n",
    "                                hist_feat=HIST_FEAT, spatial_feat=SPATIAL_FEAT)\n",
    "\n",
    "notcar_features = extract_features(notcar_img_names, color_space=COLORSPACE, orient=ORIENTATION,\n",
    "                                pix_per_cell=PIX_PER_CELL, cell_per_block=CELL_PER_BLOCK,\n",
    "                                hog_channel=HOG_CHANNEL, \n",
    "                                hist_feat=HIST_FEAT, spatial_feat=SPATIAL_FEAT)\n",
    "print(\"Seconds to extract HOG features: {:.3f}\".format(time.time()-t0))\n",
    "\n",
    "# Combine car features and non-car features into one array\n",
    "X = np.vstack([car_features, notcar_features])\n",
    "\n",
    "if HIST_FEAT or SPATIAL_FEAT:\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "else:\n",
    "    X_scaler = None\n",
    "    # Scaling is not needed if only HOGs are used\n",
    "    scaled_X = X\n",
    "\n",
    "# Create the labels vector\n",
    "labels = np.hstack([np.ones(len(car_img_names)), np.zeros(len(notcar_img_names))])\n",
    "\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle and split the data and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size = 0.2,\n",
    "                                                    random_state=np.random.randint(0, 100))\n",
    "\n",
    "# Use a linear SVC as classifier\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "t0 = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Seconds to train the classifier: {:.3f}\".format(time.time()-t0))\n",
    "\n",
    "# Check that accuracy of the classifier\n",
    "acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(\"Accuracy of the classifier: {:.3f}%\".format(acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to detect the cars\n",
    "This code was partly taken form the lesson materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, color_space, orient, pix_per_cell, cell_per_block, spatial_size=(32, 32), hist_bins=32, show_boxes=False):\n",
    "\n",
    "    if show_boxes:\n",
    "        colors = [(0,0,255), (0,255,255), (0,255,0), (255,255,0), (255,0,0), (255,0,255), (255,255,255)]\n",
    "#    print(\"orient:\", orient, \" pix/cell:\", pix_per_cell, \" cell/block:\", cell_per_block) #, \" spatial:\", spatial_size, \" bins:\", hist_bins)\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv=\"RGB2\"+color_space)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    boxes = []\n",
    "    for xb in range(nxsteps+1):\n",
    "        for yb in range(nysteps+1):\n",
    "            features = []\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            if HIST_FEAT or SPATIAL_FEAT:\n",
    "                # Use spatial features and color histograms\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                if SPATIAL_FEAT:\n",
    "                    # Get color features\n",
    "                    spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                if HIST_FEAT:\n",
    "                    hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))\n",
    "                test_prediction = svc.predict(test_features)\n",
    "            else:\n",
    "                # Do not use spatial features and color histograms\n",
    "                test_prediction = svc.predict(hog_features)\n",
    "\n",
    "            xbox_left = np.int(xleft*scale)\n",
    "            ybox_top = np.int(ytop*scale) + ystart\n",
    "            ytop_draw = np.int(ytop*scale)\n",
    "            win_size = np.int(window*scale)\n",
    "\n",
    "            if show_boxes:\n",
    "#                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_size,ytop_draw+win_size+ystart),(0,0,255),6) \n",
    "                cv2.rectangle(draw_img,(xbox_left, ybox_top),(xbox_left+win_size,ybox_top+win_size),colors[yb],3) \n",
    "\n",
    "            if test_prediction == 1:\n",
    "                boxes.append([xbox_left, ybox_top, win_size])\n",
    "    if show_boxes:\n",
    "        return np.array(boxes), draw_img\n",
    "    else:\n",
    "        return np.array(boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a test image and find the cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, value):\n",
    "    heatmap[heatmap < value] = 0\n",
    "    return heatmap\n",
    "\n",
    "heatmap_smooth = None\n",
    "\n",
    "def process_img(img):\n",
    "    global heatmap_smooth\n",
    "    img_out = np.copy(img)\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    boxes = []\n",
    "    cars = []\n",
    "\n",
    "    scale_dim = {1.0: (400, 492),\n",
    "                 1.5: (400, 528),\n",
    "                 2.0: (400, 560),\n",
    "                 2.5: (400, 600),\n",
    "                 3.0: (400, 592),\n",
    "                }\n",
    "\n",
    "    for s in scale_dim:\n",
    "        found = find_cars(img, scale_dim[s][0], scale_dim[s][1], s, \n",
    "                               svc=clf, X_scaler=X_scaler, color_space=COLORSPACE, \n",
    "                               orient=ORIENTATION, pix_per_cell=PIX_PER_CELL, \n",
    "                               cell_per_block=CELL_PER_BLOCK)\n",
    "        if len(found) > 0:\n",
    "            boxes.append(found)\n",
    "            \n",
    "    if len(boxes) > 0:\n",
    "        for b in np.concatenate(boxes):\n",
    "            color = COLORS[b[2]]\n",
    "            cv2.rectangle(img_out, (b[0], b[1]), (b[0]+b[2], b[1]+b[2]), color, 2)\n",
    "            heatmap[b[1]:b[1]+b[2], b[0]:b[0]+b[2]] += 1\n",
    "\n",
    "        heatmap_smooth *= 5\n",
    "        heatmap_smooth //= 10\n",
    "        heatmap_smooth += heatmap\n",
    "\n",
    "        # Apply threshold to the heat map\n",
    "        heatmap_thresh = apply_threshold(np.copy(heatmap_smooth), 2)\n",
    "        # Assign labels\n",
    "        labels, num_labels = label(heatmap_thresh)\n",
    "\n",
    "        # Draw bounding rectangles\n",
    "        img_draw = np.copy(img)\n",
    "        for car_id in range(1, num_labels+1):\n",
    "            nonzero = (labels == car_id).nonzero()\n",
    "            if len(nonzero[0]) > 0:\n",
    "                nonzerox = np.array(nonzero[1])\n",
    "                nonzeroy = np.array(nonzero[0])\n",
    "                bbox = ((np.max(nonzerox)+np.min(nonzerox))//2, (np.max(nonzeroy)+np.min(nonzeroy))//2,\n",
    "                        np.max(nonzerox) - np.min(nonzerox), np.max(nonzeroy) - np.min(nonzeroy))\n",
    "                cars.append(bbox)\n",
    "    return cars, heatmap_smooth, img_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = { 64: (0,0,255),\n",
    "           96: (0,255,255),\n",
    "          128: (0,255,0),\n",
    "          160: (255,255,0),\n",
    "          192: (255,0,0)}\n",
    "#img = mpimg.imread(\"tmp/project_frame_734.jpg\")\n",
    "img = mpimg.imread(\"test_images/test4.jpg\")\n",
    "\n",
    "img_draw = np.copy(img)\n",
    "heatmap_smooth = np.zeros_like(img[:,:,0])\n",
    "\n",
    "if False:\n",
    "    found, img_out = find_cars(img, 400, 492, 1.0, \n",
    "                           svc=clf, X_scaler=X_scaler, color_space=COLORSPACE, \n",
    "                           orient=ORIENTATION, pix_per_cell=PIX_PER_CELL, \n",
    "                           cell_per_block=CELL_PER_BLOCK, show_boxes=True)\n",
    "else:\n",
    "    t0 = time.time()\n",
    "    cars, heatmap, img_out = process_img(img)  \n",
    "    print(\"Processing took {:.3f} seconds\".format(time.time()-t0))\n",
    "    cars.sort()\n",
    "    for c in cars:\n",
    "        xleft = c[0]-c[2]//2\n",
    "        xright = c[0]+c[2]//2\n",
    "        ytop  = c[1]-c[3]//2\n",
    "        ybottom = c[1]+c[3]//2\n",
    "        cv2.rectangle(img_draw, (xleft, ytop), (xright, ybottom), (0,0,255), 6)\n",
    "\n",
    "f, sub = plt.subplots(3, 1, figsize=(60,20))\n",
    "sub[0].imshow(img_out)\n",
    "sub[0].set_title(\"Boxes\")\n",
    "sub[1].imshow(heatmap, cmap=\"gray\")\n",
    "sub[1].set_title(\"Heatmap after applying threshold\")\n",
    "sub[2].imshow(img_draw)\n",
    "sub[2].set_title(\"Found cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the video: \"project\" or \"test\"\n",
    "video_name = \"project\"\n",
    "\n",
    "frame_name = \"tmp/{:s}_frame_{:d}.jpg\"\n",
    "frames_to_save = [16, 24, 613, 734, 1046, 1103]\n",
    "\n",
    "NUM_PREV_CARS = 10\n",
    "\n",
    "def process_video_frame(img):\n",
    "    process_video_frame.frame_no += 1\n",
    "    \n",
    "    if process_video_frame.frame_no in frames_to_save:\n",
    "        mpimg.imsave(frame_name.format(video_name, process_video_frame.frame_no), img)\n",
    "    \n",
    "    if len(process_video_frame.prev_cars) > NUM_PREV_CARS:\n",
    "        del process_video_frame.prev_cars[0]\n",
    "\n",
    "    cars, heatmap, img_out = process_img(img) \n",
    "    cars.sort()\n",
    "    \n",
    "    filt_cars = []\n",
    "    for c in cars:\n",
    "        c_count = 0\n",
    "        for i in range(len(process_video_frame.prev_cars)):\n",
    "            prev_cars = process_video_frame.prev_cars[i]\n",
    "            max_dist = (NUM_PREV_CARS-i)*20\n",
    "            for pc in prev_cars:\n",
    "                if (pc[0]-max_dist) < c[0] and c[0] < (pc[0]+max_dist):\n",
    "                    c_count += 1\n",
    "                    break\n",
    "        if c_count >= NUM_PREV_CARS-2:\n",
    "            xleft = c[0]-c[2]//2\n",
    "            xright = c[0]+c[2]//2\n",
    "            ytop  = c[1]-c[3]//2\n",
    "            ybottom = c[1]+c[3]//2\n",
    "            cv2.rectangle(img, (xleft, ytop), (xright, ybottom), (0,0,255), 6)\n",
    "\n",
    "    process_video_frame.prev_cars.append(cars)\n",
    "\n",
    "    cv2.putText(img, \"Frame: {:d}\".format(process_video_frame.frame_no), \n",
    "                (50,50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255))\n",
    "\n",
    "#    small_heatmap = cv2.cvtColor(cv2.resize(np.copy(heatmap)*30, \n",
    "#                                            (heatmap.shape[1]//2, heatmap.shape[0]//2)),\n",
    "#                                             cv2.COLOR_GRAY2BGR)\n",
    "#    img[0:small_heatmap.shape[0], img.shape[1]-small_heatmap.shape[1]:img.shape[1], :] = small_heatmap\n",
    "    return img\n",
    "\n",
    "heatmap_smooth = np.zeros_like(img[:,:,0])\n",
    "\n",
    "process_video_frame.frame_no = 0\n",
    "process_video_frame.prev_cars = []\n",
    "video_out_name = \"./output_images/{:s}_video.mp4\".format(video_name)\n",
    "video_in = VideoFileClip(\"{:s}_video.mp4\".format(video_name))\n",
    "video_out = video_in.fl_image(process_video_frame)\n",
    "%time video_out.write_videofile(video_out_name, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
